{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7902961,"sourceType":"datasetVersion","datasetId":4641663}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/fake-news-detection/fake_and_real_news.csv')\n\n# Follow with preprocessing and model training steps...\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-15T00:38:52.999011Z","iopub.execute_input":"2024-04-15T00:38:52.999442Z","iopub.status.idle":"2024-04-15T00:38:53.349875Z","shell.execute_reply.started":"2024-04-15T00:38:52.999410Z","shell.execute_reply":"2024-04-15T00:38:53.348648Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\n# Data preprocessing function\ndef clean_text(text):\n    text = text.lower()  # Lowercase text\n    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)  # Remove single characters\n    text = re.sub(r'\\s+', ' ', text, flags=re.I)  # Replace multiple spaces with a single space\n    return text\n\n# Apply the cleaning function to the Text column\ndata['Text'] = data['Text'].apply(clean_text)\n\n# Initialize the TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\n\n# Splitting the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(data['Text'], data['label'], test_size=0.2, random_state=42)\n\n# Fit and transform the vectorizer on the training data, and transform the testing data\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)\n\n# Initialize and train the Logistic Regression model\nlog_reg = LogisticRegression(random_state=42, max_iter=1000)\nlog_reg.fit(X_train_tfidf, y_train)\n\n# Predicting the labels for the testing set\ny_pred = log_reg.predict(X_test_tfidf)\n\n# Calculate accuracy and other performance metrics\naccuracy = accuracy_score(y_test, y_pred)\nperformance_report = classification_report(y_test, y_pred)\n\n# Output the results\nprint(\"Accuracy of the model:\", accuracy)\nprint(\"Performance Report:\\n\", performance_report)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T00:45:29.029311Z","iopub.execute_input":"2024-04-15T00:45:29.030606Z","iopub.status.idle":"2024-04-15T00:45:40.615149Z","shell.execute_reply.started":"2024-04-15T00:45:29.030567Z","shell.execute_reply":"2024-04-15T00:45:40.614036Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Accuracy of the model: 0.9924242424242424\nPerformance Report:\n               precision    recall  f1-score   support\n\n        Fake       0.99      0.99      0.99       973\n        Real       0.99      0.99      0.99      1007\n\n    accuracy                           0.99      1980\n   macro avg       0.99      0.99      0.99      1980\nweighted avg       0.99      0.99      0.99      1980\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here are some recommendations and conclusions based on the analysis we performed on the dataset of fake and real news articles using a machine learning classification approach:\n\n### Conclusions\n1. **High Performance**: The Logistic Regression model achieved an accuracy of approximately 99.24%, along with high precision, recall, and F1-score for both fake and real news categories. This suggests that the model is very effective at distinguishing between fake and real news based on the textual content.\n\n2. **Effective Preprocessing**: The preprocessing steps, including text cleaning and TF-IDF vectorization, proved to be effective for this task. Simplifying the text into a format that the model can efficiently process and learn from is crucial for achieving high accuracy.\n\n3. **Balance in Data**: The near equal distribution of fake and real news articles in the dataset likely contributed to the balanced performance metrics across the two categories, suggesting that the dataset was well-prepared for a classification task.\n\n### Recommendations\n1. **Cross-Validation**: Implement cross-validation to better understand the model's stability and to check for overfitting. Although the model performed exceptionally well, cross-validation can help confirm that these results will generalize to unseen data.\n\n2. **Experiment with Other Models**: While Logistic Regression performed well, exploring other models like Support Vector Machines, Decision Trees, or advanced neural networks could provide insights into potentially better or more robust classification methods.\n\n3. **Feature Engineering**: Consider experimenting with different NLP features like word embeddings (e.g., Word2Vec, GloVe) or using bigrams and trigrams in TF-IDF vectorization to capture more context within the text, which might improve the modelâ€™s ability to understand subtler distinctions in the language used in fake vs. real news.\n\n4. **Sentiment Analysis**: Integrating sentiment analysis could offer additional insights, as fake news might systematically differ in emotion or sentiment compared to real news. This could be an additional feature for the classification models.\n\n5. **Deployment Considerations**: If planning to deploy this model, consider setting up a monitoring system to track its performance over time and to catch any drift in data characteristics or model performance. Continuous evaluation and model updating will be crucial as language and news content evolve.\n\n6. **Ethical and Bias Considerations**: It's important to continuously evaluate the model for biases, especially against certain topics or demographic groups that could be disproportionately represented in the training data. Ensuring fairness and avoiding amplification of biases are critical in applications like news classification.\n\nThese steps will help in refining the model, potentially increasing its accuracy and robustness, and preparing it for practical deployment if needed.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}